# -*- coding: utf-8 -*-
import asyncio
import json
import httpx
import os
import sys
from datetime import datetime
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from anthropic import Anthropic
from dotenv import load_dotenv

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())

load_dotenv()

app = FastAPI(
    title="DA-ZZANY Chat Backend",
    description="ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ë°±ì—”ë“œ ì„œë²„ - n8n ìë™í™” ì „ë¬¸ê°€ Claude",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str
    session_id: str = "default"

class DAZZANYChatBackend:
    def __init__(self):
        # Anthropic Claude API ì„¤ì •
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            print("ê²½ê³ : ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ì˜ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.anthropic = None
            self.mock_mode = True
        else:
            self.anthropic = Anthropic(api_key=api_key)
            self.mock_mode = False
            
        # MCP ì„¤ì • (n8n ì›Œí¬í”Œë¡œìš° ìë™í™” ë„êµ¬)
        self.mcp_url = "http://localhost:3000/mcp"
        self.auth_token = "4PsvmU2knXt+KTV+d2sOFTly6C9C+9QAwdbqnd9uFVw="
        self.tools = []
        self.sessions = {}  # ì„¸ì…˜ë³„ ëŒ€í™” ì €ì¥
        
        mode_text = "Mock" if self.mock_mode else "Claude API"
        print(f"DA-ZZANY ì±„íŒ… ë°±ì—”ë“œ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë“œ: {mode_text})")
        
    async def init_mcp(self):
        if self.tools:  # ì´ë¯¸ ì´ˆê¸°í™”ë¨
            return
            
        headers = {"Authorization": f"Bearer {self.auth_token}"}
        async with httpx.AsyncClient() as client:
            await client.post(self.mcp_url, json={
                "jsonrpc": "2.0", "id": 1, "method": "initialize",
                "params": {"protocolVersion": "2024-11-05", "capabilities": {},
                          "clientInfo": {"name": "claude-mcp-backend", "version": "1.0"}}
            }, headers=headers)
            
            response = await client.post(self.mcp_url, json={
                "jsonrpc": "2.0", "id": 2, "method": "tools/list"
            }, headers=headers)
            
            self.tools = response.json()["result"]["tools"]
            print(f"[{datetime.now().strftime('%H:%M:%S')}] MCP ë„êµ¬ {len(self.tools)}ê°œ ë¡œë“œ ì™„ë£Œ")
    
    def convert_tools(self):
        return [{
            "name": tool["name"],
            "description": tool.get("description", ""),
            "input_schema": tool.get("inputSchema", {"type": "object", "properties": {}})
        } for tool in self.tools]
    
    async def call_tool(self, name, args):
        headers = {"Authorization": f"Bearer {self.auth_token}"}
        async with httpx.AsyncClient() as client:
            response = await client.post(self.mcp_url, json={
                "jsonrpc": "2.0", "id": 3, "method": "tools/call",
                "params": {"name": name, "arguments": args}
            }, headers=headers)
            
            result = response.json().get("result", {})
            return json.dumps(result.get("content", result), ensure_ascii=False, indent=2)
    
    def get_session_messages(self, session_id):
        if session_id not in self.sessions:
            self.sessions[session_id] = []
        return self.sessions[session_id]
    
    def add_cache_control_to_messages(self, messages):
        if len(messages) >= 1:
            # ëª¨ë“  ë©”ì‹œì§€ë¥¼ í‘œì¤€ í˜•íƒœë¡œ ë³€í™˜í•˜ê³  ê¸°ì¡´ ìºì‹œ ì»¨íŠ¸ë¡¤ ì œê±°
            for msg in messages:
                if isinstance(msg.get("content"), str):
                    msg["content"] = [{"type": "text", "text": msg["content"]}]
                elif isinstance(msg.get("content"), list):
                    for block in msg["content"]:
                        if isinstance(block, dict) and "cache_control" in block:
                            del block["cache_control"]
            
            # ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ ìºì‹œ - ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— ìºì‹œ ì»¨íŠ¸ë¡¤ ì ìš©
            if messages:
                last_msg = messages[-1]
                if isinstance(last_msg.get("content"), list) and last_msg["content"]:
                    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì˜ ë§ˆì§€ë§‰ ë¸”ë¡ì— ìºì‹œ ì»¨íŠ¸ë¡¤ ì¶”ê°€
                    last_block = last_msg["content"][-1]
                    if isinstance(last_block, dict):
                        last_block["cache_control"] = {"type": "ephemeral"}
    
    async def chat_stream(self, message: str, session_id: str):
        """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì²˜ë¦¬"""
        # Mock ëª¨ë“œì¼ ë•ŒëŠ” ê°„ë‹¨í•œ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
        if self.mock_mode:
            async for chunk in self._mock_chat_stream(message, session_id):
                yield chunk
            return
            
        # ì‹¤ì œ Claude API ìŠ¤íŠ¸ë¦¬ë°
        await self.init_mcp()
        
        messages = self.get_session_messages(session_id)
        messages.append({"role": "user", "content": message})
        
        self.add_cache_control_to_messages(messages)
        
        # ë””ë²„ê¹…: ìºì‹œ ì»¨íŠ¸ë¡¤ ì ìš© í™•ì¸
        print(f"[{datetime.now().strftime('%H:%M:%S')}] DEBUG - Messages count: {len(messages)}")
        cache_control_count = 0
        for i, msg in enumerate(messages):
            if isinstance(msg.get('content'), list):
                for j, block in enumerate(msg['content']):
                    if isinstance(block, dict) and 'cache_control' in block:
                        cache_control_count += 1
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] DEBUG - Cache control found in message {i} ({msg['role']}), block {j}")
        print(f"[{datetime.now().strftime('%H:%M:%S')}] DEBUG - Total cache controls: {cache_control_count}")
        
        while True:
            # ë„êµ¬ ëª©ë¡ì„ ìºì‹œ ê°€ëŠ¥í•œ í˜•íƒœë¡œ êµ¬ì„±
            tools = self.convert_tools()
            if tools:  # ë§ˆì§€ë§‰ ë„êµ¬ì— ìºì‹œ ì»¨íŠ¸ë¡¤ ì¶”ê°€
                tools[-1]["cache_control"] = {"type": "ephemeral"}
            
            with self.anthropic.messages.stream(
                model="claude-sonnet-4-20250514",
                max_tokens=16000,
                thinking={"type": "enabled", "budget_tokens": 10000},
                tools=tools,
                system=[{
                    "type": "text",
                    "text": "ë‹¹ì‹ ì€ DA-ZZANYì˜ n8n ìë™í™” ì›Œí¬í”Œë¡œìš° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì›Œí¬í”Œë¡œìš° ìë™í™”ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´ n8n-MCP ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ì„¸ìš”. ë…¸ë“œ ë°°ì¹˜ ì‹œ input/outputì„ ëª…í™•íˆ ì„¤ëª…í•˜ê³ , í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.",
                    "cache_control": {"type": "ephemeral"}
                }],
                extra_headers={"anthropic-beta": "interleaved-thinking-2025-05-14"},
                messages=messages
            ) as stream:
                
                thinking_text = ""
                current_block_type = None
                
                for event in stream:
                    if event.type == "content_block_start":
                        current_block_type = event.content_block.type
                        if current_block_type == "thinking":
                            yield f"data: {json.dumps({'type': 'thinking_start'})}\n\n"
                        elif current_block_type == "text":
                            yield f"data: {json.dumps({'type': 'text_start'})}\n\n"
                        elif current_block_type == "tool_use":
                            yield f"data: {json.dumps({'type': 'tool_use_start', 'name': event.content_block.name})}\n\n"
                    
                    elif event.type == "content_block_delta":
                        if event.delta.type == "thinking_delta":
                            thinking_text += event.delta.thinking
                            # ì›ë³¸ deltaë¥¼ ê·¸ëŒ€ë¡œ ì „ì†¡
                            yield f"data: {json.dumps({'type': 'thinking_delta', 'text': event.delta.thinking})}\n\n"
                            await asyncio.sleep(0)  # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ë‹¤ë¥¸ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡
                        elif event.delta.type == "text_delta":
                            # ì›ë³¸ deltaë¥¼ ê·¸ëŒ€ë¡œ ì „ì†¡  
                            yield f"data: {json.dumps({'type': 'text_delta', 'text': event.delta.text})}\n\n"
                            await asyncio.sleep(0)  # ì´ë²¤íŠ¸ ë£¨í”„ê°€ ë‹¤ë¥¸ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡
                    
                    elif event.type == "content_block_stop":
                        if current_block_type == "thinking":
                            yield f"data: {json.dumps({'type': 'thinking_stop'})}\n\n"
                            thinking_text = ""
                
                # Usage ë¡œê·¸ ì¶œë ¥ ë° ë©”ì‹œì§€ ì¶”ì¶œ
                message = stream.get_final_message()
                usage = message.usage
                
                # ì˜¬ë°”ë¥¸ ìºì‹œ ì†ì„±ëª… ì‚¬ìš©
                cache_read = getattr(usage, 'cache_read_input_tokens', 0)
                cache_creation = getattr(usage, 'cache_creation_input_tokens', 0)
                
                print(f"[{datetime.now().strftime('%H:%M:%S')}] USAGE - Input: {usage.input_tokens}, Output: {usage.output_tokens}, Cache Create: {cache_creation}, Cache Read: {cache_read}")
                tool_blocks = [b for b in message.content if b.type == 'tool_use']
                
                if not tool_blocks:
                    yield f"data: {json.dumps({'type': 'complete'})}\n\n"
                    break
                
                messages.append({"role": "assistant", "content": message.content})
                
                # ë„êµ¬ ì‹¤í–‰
                tool_results = []
                for tool in tool_blocks:
                    yield f"data: {json.dumps({'type': 'tool_execution', 'name': tool.name, 'input': tool.input})}\n\n"
                    
                    try:
                        result = await self.call_tool(tool.name, tool.input)
                        yield f"data: {json.dumps({'type': 'tool_result', 'name': tool.name, 'result': result[:200] + ('...' if len(result) > 200 else '')})}\n\n"
                        
                        tool_results.append({
                            "type": "tool_result",
                            "tool_use_id": tool.id,
                            "content": result
                        })
                    except Exception as e:
                        error_msg = str(e)
                        yield f"data: {json.dumps({'type': 'tool_error', 'name': tool.name, 'error': error_msg})}\n\n"
                        tool_results.append({
                            "type": "tool_result",
                            "tool_use_id": tool.id,
                            "content": f"ì˜¤ë¥˜: {error_msg}"
                        })
                
                messages.append({"role": "user", "content": tool_results})
                
                # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ìºì‹œ ì»¨íŠ¸ë¡¤ ì ìš©
                self.add_cache_control_to_messages(messages)
    
    async def _mock_chat_stream(self, message: str, session_id: str):
        """ëª¨ì˜ ì±„íŒ… ìŠ¤íŠ¸ë¦¬ë° (ìºë”” APIê°€ ì—†ì„ ë•Œ)"""
        # ì„¸ì…˜ ì²˜ë¦¬
        messages = self.get_session_messages(session_id)
        messages.append({"role": "user", "content": message})
        
        # ì‘ë‹µ ìƒì„±
        response = self._generate_mock_response(message)
        
        # ì‚¬ê³  ë‹¨ê³„ ì‹œë®¬ë ˆì´ì…˜
        yield f"data: {json.dumps({'type': 'thinking_start'})}\n\n"
        await asyncio.sleep(0.3)
        yield f"data: {json.dumps({'type': 'thinking_delta', 'text': 'ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'})}\n\n"
        await asyncio.sleep(0.5)
        yield f"data: {json.dumps({'type': 'thinking_delta', 'text': ' ì ì ˆí•œ ì‘ë‹µì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤.'})}\n\n"
        await asyncio.sleep(0.3)
        yield f"data: {json.dumps({'type': 'thinking_stop'})}\n\n"
        
        # í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°
        yield f"data: {json.dumps({'type': 'text_start'})}\n\n"
        
        # ë¬¸ìë¥¼ ì¡°ê¸ˆì”© ìŠ¤íŠ¸ë¦¬ë°
        for char in response:
            yield f"data: {json.dumps({'type': 'text_delta', 'text': char})}\n\n"
            await asyncio.sleep(0.02)  # íƒ€ì´í•‘ íš¨ê³¼
        
        # ì™„ë£Œ
        yield f"data: {json.dumps({'type': 'complete'})}\n\n"
        
        # ì„¸ì…˜ì— ì‘ë‹µ ì €ì¥
        messages.append({"role": "assistant", "content": response})
    
    def _generate_mock_response(self, message: str) -> str:
        """ëª¨ì˜ ì‘ë‹µ ìƒì„±"""
        message_lower = message.lower()
        
        if "ì•ˆë…•" in message_lower or "hello" in message_lower:
            return "ì•ˆë…•í•˜ì„¸ìš”! ğŸš€ DA-ZZANYì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ì €ëŠ” n8n ì›Œí¬í”Œë¡œìš° ìë™í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì–´ë–¤ ì‘ì—…ì„ ìë™í™”í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"
        elif "ì›Œí¬í”Œë¡œìš°" in message_lower or "workflow" in message_lower:
            return "ğŸ”§ ì›Œí¬í”Œë¡œìš° ìë™í™”ì— ëŒ€í•œ ì§ˆë¬¸ì´ì‹œêµ°ìš”! n8nì„ í™œìš©í•œ ë‹¤ì–‘í•œ ìë™í™” ì†”ë£¨ì…˜ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´:\n\nâ€¢ ë°ì´í„° ì²˜ë¦¬ ë° ë³€í™˜\nâ€¢ API ì—°ë™ ë° ë°ì´í„° ë™ê¸°í™”\nâ€¢ ì´ë©”ì¼ ìë™í™” ë° ì•Œë¦¼\nâ€¢ íŒŒì¼ ì²˜ë¦¬ ë° ë°±ì—…\nâ€¢ ì†Œì…œ ë¯¸ë””ì–´ ìë™ ê²Œì‹œ\n\nì–´ë–¤ ì¢…ë¥˜ì˜ ìë™í™”ë¥¼ ì›í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”!"
        elif "ì±„íŒ…" in message_lower or "chat" in message_lower:
            return "ğŸ’¬ ì‹¤ì‹œê°„ ì±„íŒ… ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤! ì´ ì‹œìŠ¤í…œì€ Server-Sent Eventsë¥¼ í†µí•´ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì§€ì›í•˜ë©°, ì‚¬ê³  ê³¼ì •(thinking)ê³¼ ë„êµ¬ ì‹¤í–‰ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        elif "n8n" in message_lower:
            return "ğŸš¬ n8nì€ ê°•ë ¥í•œ ì›Œí¬í”Œë¡œìš° ìë™í™” ë„êµ¬ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë…¸ë“œë¥¼ ì—°ê²°í•˜ì—¬ ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹ì • n8n ê¸°ëŠ¥ì— ëŒ€í•´ ë” ì•Œê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë¶€ë¶„ì´ ê¶ê¸ˆí•œì§€ ì•Œë ¤ì£¼ì„¸ìš”!"
        else:
            return f"ğŸ¤” '{message}'ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›Œí¬í”Œë¡œìš° ìë™í™”ì™€ ê´€ë ¨ëœ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
chat_backend = DAZZANYChatBackend()

@app.post("/chat")
async def chat(request: ChatRequest):
    try:
        return StreamingResponse(
            chat_backend.chat_stream(request.message, request.session_id),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"  # nginx ë²„í¼ë§ ë¹„í™œì„±í™”
            }
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "DA-ZZANY Chat Backend API",
        "version": "1.0.0",
        "description": "n8n ì›Œí¬í”Œë¡œìš° ìë™í™” ì „ë¬¸ê°€ Claude",
        "endpoints": {
            "/chat": "POST - ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…",
            "/health": "GET - ì„œë²„ ìƒíƒœ í™•ì¸",
            "/sessions/{session_id}/messages": "GET - ì„¸ì…˜ ë©”ì‹œì§€ ê¸°ë¡",
            "/sessions/{session_id}": "DELETE - ì„¸ì…˜ ì´ˆê¸°í™”"
        }
    }

@app.get("/health")
async def health():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy",
        "backend": "DA-ZZANY Chat Backend",
        "mode": "Mock" if chat_backend.mock_mode else "Claude API",
        "tools_loaded": len(chat_backend.tools),
        "sessions": len(chat_backend.sessions),
        "timestamp": datetime.now().isoformat()
    }

@app.get("/sessions/{session_id}/messages")
async def get_session_messages(session_id: str):
    """íŠ¹ì • ì„¸ì…˜ì˜ ë©”ì‹œì§€ ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°"""
    messages = chat_backend.get_session_messages(session_id)
    return {
        "session_id": session_id,
        "messages": messages,
        "count": len(messages)
    }

@app.delete("/sessions/{session_id}")
async def clear_session(session_id: str):
    """ì„¸ì…˜ ì´ˆê¸°í™”"""
    if session_id in chat_backend.sessions:
        del chat_backend.sessions[session_id]
        return {"message": f"ì„¸ì…˜ {session_id}ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."}
    else:
        raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

@app.get("/sessions")
async def list_sessions():
    """ëª¨ë“  ì„¸ì…˜ ëª©ë¡ ë° ì •ë³´"""
    sessions_info = []
    for session_id, messages in chat_backend.sessions.items():
        sessions_info.append({
            "session_id": session_id,
            "message_count": len(messages),
            "last_message": messages[-1] if messages else None
        })
    
    return {
        "total_sessions": len(chat_backend.sessions),
        "sessions": sessions_info
    }

if __name__ == "__main__":
    import uvicorn
    
    print("DA-ZZANY ì±„íŒ… ë°±ì—”ë“œ ì„œë²„ ì‹œì‘ ì¤‘...")
    mode_text = "Mock (ë¯¸ë¦¬ë³´ê¸°)" if chat_backend.mock_mode else "Claude API (ì‹¤ì œ)"
    print(f"ëª¨ë“œ: {mode_text}")
    print("ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ì¤‘ë‹¨í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”\n")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000,
        reload=True,  # ê°œë°œ ëª¨ë“œì—ì„œ ìë™ ì¬ì‹œì‘
        log_level="info"
    )